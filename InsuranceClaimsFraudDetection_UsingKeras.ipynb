{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Insurance Claims Fraud Detection</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Problem\n",
    "\n",
    "An insurance company has approached you with a dataset of previous claims of their clients. The insurance company wants you to develop a model to help them predict which claims look fraudulent. By doing so you hope to save the company millions of dollars annually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>age</th>\n",
       "      <th>policy_number</th>\n",
       "      <th>policy_bind_date</th>\n",
       "      <th>policy_state</th>\n",
       "      <th>policy_csl</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <th>umbrella_limit</th>\n",
       "      <th>insured_zip</th>\n",
       "      <th>...</th>\n",
       "      <th>witnesses</th>\n",
       "      <th>police_report_available</th>\n",
       "      <th>total_claim_amount</th>\n",
       "      <th>injury_claim</th>\n",
       "      <th>property_claim</th>\n",
       "      <th>vehicle_claim</th>\n",
       "      <th>auto_make</th>\n",
       "      <th>auto_model</th>\n",
       "      <th>auto_year</th>\n",
       "      <th>fraud_reported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>328</td>\n",
       "      <td>48</td>\n",
       "      <td>521585</td>\n",
       "      <td>2014-10-17</td>\n",
       "      <td>OH</td>\n",
       "      <td>250/500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1406.91</td>\n",
       "      <td>0</td>\n",
       "      <td>466132</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>YES</td>\n",
       "      <td>71610</td>\n",
       "      <td>6510</td>\n",
       "      <td>13020</td>\n",
       "      <td>52080</td>\n",
       "      <td>Saab</td>\n",
       "      <td>92x</td>\n",
       "      <td>2004</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228</td>\n",
       "      <td>42</td>\n",
       "      <td>342868</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>IN</td>\n",
       "      <td>250/500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1197.22</td>\n",
       "      <td>5000000</td>\n",
       "      <td>468176</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>?</td>\n",
       "      <td>5070</td>\n",
       "      <td>780</td>\n",
       "      <td>780</td>\n",
       "      <td>3510</td>\n",
       "      <td>Mercedes</td>\n",
       "      <td>E400</td>\n",
       "      <td>2007</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>134</td>\n",
       "      <td>29</td>\n",
       "      <td>687698</td>\n",
       "      <td>2000-09-06</td>\n",
       "      <td>OH</td>\n",
       "      <td>100/300</td>\n",
       "      <td>2000</td>\n",
       "      <td>1413.14</td>\n",
       "      <td>5000000</td>\n",
       "      <td>430632</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>NO</td>\n",
       "      <td>34650</td>\n",
       "      <td>7700</td>\n",
       "      <td>3850</td>\n",
       "      <td>23100</td>\n",
       "      <td>Dodge</td>\n",
       "      <td>RAM</td>\n",
       "      <td>2007</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>256</td>\n",
       "      <td>41</td>\n",
       "      <td>227811</td>\n",
       "      <td>1990-05-25</td>\n",
       "      <td>IL</td>\n",
       "      <td>250/500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1415.74</td>\n",
       "      <td>6000000</td>\n",
       "      <td>608117</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NO</td>\n",
       "      <td>63400</td>\n",
       "      <td>6340</td>\n",
       "      <td>6340</td>\n",
       "      <td>50720</td>\n",
       "      <td>Chevrolet</td>\n",
       "      <td>Tahoe</td>\n",
       "      <td>2014</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228</td>\n",
       "      <td>44</td>\n",
       "      <td>367455</td>\n",
       "      <td>2014-06-06</td>\n",
       "      <td>IL</td>\n",
       "      <td>500/1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1583.91</td>\n",
       "      <td>6000000</td>\n",
       "      <td>610706</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NO</td>\n",
       "      <td>6500</td>\n",
       "      <td>1300</td>\n",
       "      <td>650</td>\n",
       "      <td>4550</td>\n",
       "      <td>Accura</td>\n",
       "      <td>RSX</td>\n",
       "      <td>2009</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   months_as_customer  age  policy_number policy_bind_date policy_state  \\\n",
       "0                 328   48         521585       2014-10-17           OH   \n",
       "1                 228   42         342868       2006-06-27           IN   \n",
       "2                 134   29         687698       2000-09-06           OH   \n",
       "3                 256   41         227811       1990-05-25           IL   \n",
       "4                 228   44         367455       2014-06-06           IL   \n",
       "\n",
       "  policy_csl  policy_deductable  policy_annual_premium  umbrella_limit  \\\n",
       "0    250/500               1000                1406.91               0   \n",
       "1    250/500               2000                1197.22         5000000   \n",
       "2    100/300               2000                1413.14         5000000   \n",
       "3    250/500               2000                1415.74         6000000   \n",
       "4   500/1000               1000                1583.91         6000000   \n",
       "\n",
       "   insured_zip      ...       witnesses police_report_available  \\\n",
       "0       466132      ...               2                     YES   \n",
       "1       468176      ...               0                       ?   \n",
       "2       430632      ...               3                      NO   \n",
       "3       608117      ...               2                      NO   \n",
       "4       610706      ...               1                      NO   \n",
       "\n",
       "  total_claim_amount injury_claim property_claim  vehicle_claim  auto_make  \\\n",
       "0              71610         6510          13020          52080       Saab   \n",
       "1               5070          780            780           3510   Mercedes   \n",
       "2              34650         7700           3850          23100      Dodge   \n",
       "3              63400         6340           6340          50720  Chevrolet   \n",
       "4               6500         1300            650           4550     Accura   \n",
       "\n",
       "  auto_model auto_year fraud_reported  \n",
       "0        92x      2004              Y  \n",
       "1       E400      2007              Y  \n",
       "2        RAM      2007              N  \n",
       "3      Tahoe      2014              Y  \n",
       "4        RSX      2009              N  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the dataset into a dataframe\n",
    "df = pd.read_csv('insurance_claims.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 39)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the shape of the dataframe\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['months_as_customer', 'age', 'policy_number', 'policy_bind_date',\n",
       "       'policy_state', 'policy_csl', 'policy_deductable',\n",
       "       'policy_annual_premium', 'umbrella_limit', 'insured_zip', 'insured_sex',\n",
       "       'insured_education_level', 'insured_occupation', 'insured_hobbies',\n",
       "       'insured_relationship', 'capital-gains', 'capital-loss',\n",
       "       'incident_date', 'incident_type', 'collision_type', 'incident_severity',\n",
       "       'authorities_contacted', 'incident_state', 'incident_city',\n",
       "       'incident_location', 'incident_hour_of_the_day',\n",
       "       'number_of_vehicles_involved', 'property_damage', 'bodily_injuries',\n",
       "       'witnesses', 'police_report_available', 'total_claim_amount',\n",
       "       'injury_claim', 'property_claim', 'vehicle_claim', 'auto_make',\n",
       "       'auto_model', 'auto_year', 'fraud_reported'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the columns of the dataframe\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 39 columns):\n",
      "months_as_customer             1000 non-null int64\n",
      "age                            1000 non-null int64\n",
      "policy_number                  1000 non-null int64\n",
      "policy_bind_date               1000 non-null object\n",
      "policy_state                   1000 non-null object\n",
      "policy_csl                     1000 non-null object\n",
      "policy_deductable              1000 non-null int64\n",
      "policy_annual_premium          1000 non-null float64\n",
      "umbrella_limit                 1000 non-null int64\n",
      "insured_zip                    1000 non-null int64\n",
      "insured_sex                    1000 non-null object\n",
      "insured_education_level        1000 non-null object\n",
      "insured_occupation             1000 non-null object\n",
      "insured_hobbies                1000 non-null object\n",
      "insured_relationship           1000 non-null object\n",
      "capital-gains                  1000 non-null int64\n",
      "capital-loss                   1000 non-null int64\n",
      "incident_date                  1000 non-null object\n",
      "incident_type                  1000 non-null object\n",
      "collision_type                 1000 non-null object\n",
      "incident_severity              1000 non-null object\n",
      "authorities_contacted          1000 non-null object\n",
      "incident_state                 1000 non-null object\n",
      "incident_city                  1000 non-null object\n",
      "incident_location              1000 non-null object\n",
      "incident_hour_of_the_day       1000 non-null int64\n",
      "number_of_vehicles_involved    1000 non-null int64\n",
      "property_damage                1000 non-null object\n",
      "bodily_injuries                1000 non-null int64\n",
      "witnesses                      1000 non-null int64\n",
      "police_report_available        1000 non-null object\n",
      "total_claim_amount             1000 non-null int64\n",
      "injury_claim                   1000 non-null int64\n",
      "property_claim                 1000 non-null int64\n",
      "vehicle_claim                  1000 non-null int64\n",
      "auto_make                      1000 non-null object\n",
      "auto_model                     1000 non-null object\n",
      "auto_year                      1000 non-null int64\n",
      "fraud_reported                 1000 non-null object\n",
      "dtypes: float64(1), int64(17), object(21)\n",
      "memory usage: 304.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#check the data types of each column\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['policy_bind_date',\n",
       " 'policy_state',\n",
       " 'policy_csl',\n",
       " 'insured_sex',\n",
       " 'insured_education_level',\n",
       " 'insured_occupation',\n",
       " 'insured_hobbies',\n",
       " 'insured_relationship',\n",
       " 'incident_date',\n",
       " 'incident_type',\n",
       " 'collision_type',\n",
       " 'incident_severity',\n",
       " 'authorities_contacted',\n",
       " 'incident_state',\n",
       " 'incident_city',\n",
       " 'incident_location',\n",
       " 'property_damage',\n",
       " 'police_report_available',\n",
       " 'auto_make',\n",
       " 'auto_model',\n",
       " 'fraud_reported']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objectcols = [col for col in df.columns if df[col].dtype == object]\n",
    "objectcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>age</th>\n",
       "      <th>policy_number</th>\n",
       "      <th>policy_bind_date</th>\n",
       "      <th>policy_csl</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <th>umbrella_limit</th>\n",
       "      <th>insured_zip</th>\n",
       "      <th>capital-gains</th>\n",
       "      <th>...</th>\n",
       "      <th>auto_model_TL</th>\n",
       "      <th>auto_model_Tahoe</th>\n",
       "      <th>auto_model_Ultima</th>\n",
       "      <th>auto_model_Wrangler</th>\n",
       "      <th>auto_model_X5</th>\n",
       "      <th>auto_model_X6</th>\n",
       "      <th>fraud_reported_Y</th>\n",
       "      <th>incident_type_Parked Car</th>\n",
       "      <th>incident_type_Single Vehicle Collision</th>\n",
       "      <th>incident_type_Vehicle Theft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>328</td>\n",
       "      <td>48</td>\n",
       "      <td>521585</td>\n",
       "      <td>2014-10-17</td>\n",
       "      <td>250/500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1406.91</td>\n",
       "      <td>0</td>\n",
       "      <td>466132</td>\n",
       "      <td>53300</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228</td>\n",
       "      <td>42</td>\n",
       "      <td>342868</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>250/500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1197.22</td>\n",
       "      <td>5000000</td>\n",
       "      <td>468176</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>134</td>\n",
       "      <td>29</td>\n",
       "      <td>687698</td>\n",
       "      <td>2000-09-06</td>\n",
       "      <td>100/300</td>\n",
       "      <td>2000</td>\n",
       "      <td>1413.14</td>\n",
       "      <td>5000000</td>\n",
       "      <td>430632</td>\n",
       "      <td>35100</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>256</td>\n",
       "      <td>41</td>\n",
       "      <td>227811</td>\n",
       "      <td>1990-05-25</td>\n",
       "      <td>250/500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1415.74</td>\n",
       "      <td>6000000</td>\n",
       "      <td>608117</td>\n",
       "      <td>48900</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228</td>\n",
       "      <td>44</td>\n",
       "      <td>367455</td>\n",
       "      <td>2014-06-06</td>\n",
       "      <td>500/1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1583.91</td>\n",
       "      <td>6000000</td>\n",
       "      <td>610706</td>\n",
       "      <td>66000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   months_as_customer  age  policy_number policy_bind_date policy_csl  \\\n",
       "0                 328   48         521585       2014-10-17    250/500   \n",
       "1                 228   42         342868       2006-06-27    250/500   \n",
       "2                 134   29         687698       2000-09-06    100/300   \n",
       "3                 256   41         227811       1990-05-25    250/500   \n",
       "4                 228   44         367455       2014-06-06   500/1000   \n",
       "\n",
       "   policy_deductable  policy_annual_premium  umbrella_limit  insured_zip  \\\n",
       "0               1000                1406.91               0       466132   \n",
       "1               2000                1197.22         5000000       468176   \n",
       "2               2000                1413.14         5000000       430632   \n",
       "3               2000                1415.74         6000000       608117   \n",
       "4               1000                1583.91         6000000       610706   \n",
       "\n",
       "   capital-gains             ...               auto_model_TL auto_model_Tahoe  \\\n",
       "0          53300             ...                           0                0   \n",
       "1              0             ...                           0                0   \n",
       "2          35100             ...                           0                0   \n",
       "3          48900             ...                           0                1   \n",
       "4          66000             ...                           0                0   \n",
       "\n",
       "   auto_model_Ultima  auto_model_Wrangler  auto_model_X5  auto_model_X6  \\\n",
       "0                  0                    0              0              0   \n",
       "1                  0                    0              0              0   \n",
       "2                  0                    0              0              0   \n",
       "3                  0                    0              0              0   \n",
       "4                  0                    0              0              0   \n",
       "\n",
       "   fraud_reported_Y  incident_type_Parked Car  \\\n",
       "0                 1                         0   \n",
       "1                 1                         0   \n",
       "2                 0                         0   \n",
       "3                 1                         0   \n",
       "4                 0                         0   \n",
       "\n",
       "   incident_type_Single Vehicle Collision  incident_type_Vehicle Theft  \n",
       "0                                       1                            0  \n",
       "1                                       0                            1  \n",
       "2                                       0                            0  \n",
       "3                                       1                            0  \n",
       "4                                       0                            1  \n",
       "\n",
       "[5 rows x 1147 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats = ['policy_state','insured_sex', 'insured_education_level','insured_occupation','insured_hobbies','insured_relationship',\\\n",
    "         'collision_type','incident_severity','authorities_contacted','incident_state','incident_city','incident_location',\\\n",
    "         'property_damage','police_report_available','auto_make','auto_model','fraud_reported','incident_type']\n",
    "df_final = pd.get_dummies(df,columns=feats,drop_first=True)\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We use sklearnâ€™s train_test_split to split the data into a training set and a test set.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_final.drop(['fraud_reported_Y','policy_csl','policy_bind_date','incident_date'],axis=1).values\n",
    "y = df_final['fraud_reported_Y'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the massive amounts of computations taking place in deep learning, feature scaling is compulsory. Feature scaling standardizes the range of our independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 1143)\n",
      "(300, 1143)\n",
      "(700,)\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train))\n",
    "print(type(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(15,0.9,'15')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEFCAYAAADqujDUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlBUAY4yJUVYAjDEmRlkBMMaYGPX/Aa1NdDNXyNpJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# apply PCA on X_train\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA().fit(X_train)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Cumulative explained variance')\n",
    "plt.annotate('15',xy=(15, .90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# individual explained variance\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.bar(range(44), pca.explained_variance_, alpha=0.5,\n",
    "            label='individual explained variance')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal components')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import keras and its modules\n",
    "import keras\n",
    "from keras.models import Sequential #Sequential module is required to initialize ANN\n",
    "from keras.layers import Dense #Dense module is required to build the layers of ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to initialize our ANN by creating an instance of Sequential. The Sequential function initializes a linear stack of layers. This allows us to add more layers later using the Dense module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Adding input layer (First Hidden Layer)</b>\n",
    "\n",
    "We use the add method to add different layers to our ANN. The first parameter is the number of nodes you want to add to this layer. There is no rule of thumb as to how many nodes you should add. However a common strategy is to choose the number of nodes as the average of nodes in the input layer and the number of nodes in the output layer.\n",
    "\n",
    "Say for example you had five independent variables and one output. Then you would take the sum of that and divide by two, which is three. You can also decide to experiment with a technique called parameter tuning. The second parameter, kernel_initializer, is the function that will be used to initialize the weights. In this case, it will use a uniform distribution to make sure that the weights are small numbers close to zero. The next parameter is the activation function. We use the Rectifier function, shortened as relu. We mostly use this function for the hidden layer in ANN. The final parameter is input_dim, which is the number of nodes in the input layer. It represents the number of independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier.add(\n",
    "        Dense(500, kernel_initializer = 'uniform',\n",
    "              activation = 'relu', input_dim=1143))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Adding Second Hidden Layer</b>\n",
    "\n",
    "Adding the second hidden layer is similar to adding the first hidden layer. \n",
    "\n",
    "We donâ€™t need to specify the input_dim parameter because we have already specified it in the first hidden layer. In the first hidden layer we specified this in order to let the layer know how many input nodes to expect. In the second hidden layer the ANN already knows how many input nodes to expect so we donâ€™t need to repeat ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.add(\n",
    "        Dense(500, kernel_initializer = 'uniform',\n",
    "              activation = 'relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Adding the Output layer</b>\n",
    "\n",
    "We change the first parameter because in our output node we expect one node. This is because we are only interested in knowing whether a claim was fraudulent or not. We change the activation function because we want to get the probabilities that a claim is fraudulent. We do this by using the Sigmoid activation function. In case youâ€™re dealing with a classification problem that has more than two classes (i.e. classifying cats, dogs, and monkeys) weâ€™d need to change two things. We â€˜d change the first parameter to 3 and change the activation function to softmax. Softmax is a sigmoid function applied to an independent variable with more than two categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.add(\n",
    "     Dense(1, kernel_initializer = 'uniform',\n",
    "           activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Compiling the ANN</b>\n",
    "\n",
    "Compiling is basically applying a stochastic gradient descent to the whole neural network. The first parameter is the algorithm you want to use to get the optimal set of weights in the neural network. The algorithm used here is a stochastic gradient algorithm. There are many variants of this. A very efficient one to use is adam. The second parameter is the loss function within the stochastic gradient algorithm. Since our categories are binary we use the binary_crossentropy loss function. Otherwise we would have used categorical_crossentopy. The final argument is the criterion weâ€™ll use to evaluate our model. In this case we use the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier.compile(optimizer= 'adam',\n",
    "                  loss = 'binary_crossentropy',\n",
    "                  metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<b>Fitting ANN to the training set</b>\n",
    "\n",
    "X_train represents the independent variables weâ€™re using to train our ANN, and y_train represents the column weâ€™re predicting. Epochs represents the number of times weâ€™re going to pass our full dataset through the ANN. Batch_size is the number of observations after which the weights will be updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.4529 - acc: 0.9000 - val_loss: 0.9810 - val_acc: 0.7500\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.2182 - acc: 0.8943 - val_loss: 1.2885 - val_acc: 0.7500\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2072 - acc: 0.9043 - val_loss: 1.3996 - val_acc: 0.7500\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.2092 - acc: 0.9043 - val_loss: 1.6714 - val_acc: 0.7500\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.2065 - acc: 0.9043 - val_loss: 1.7416 - val_acc: 0.7500\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.2041 - acc: 0.9043 - val_loss: 1.7789 - val_acc: 0.7500\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.2045 - acc: 0.9043 - val_loss: 1.9077 - val_acc: 0.7500\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.2038 - acc: 0.9043 - val_loss: 1.8930 - val_acc: 0.7500\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.2061 - acc: 0.9043 - val_loss: 1.9429 - val_acc: 0.7500\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.2057 - acc: 0.9043 - val_loss: 1.9925 - val_acc: 0.7500\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.2035 - acc: 0.9043 - val_loss: 1.9778 - val_acc: 0.7500\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.2080 - acc: 0.9043 - val_loss: 2.0507 - val_acc: 0.7500\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.2057 - acc: 0.9043 - val_loss: 2.0848 - val_acc: 0.7500\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.2043 - acc: 0.9043 - val_loss: 2.1745 - val_acc: 0.7500\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.2055 - acc: 0.9043 - val_loss: 2.2299 - val_acc: 0.7500\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.2062 - acc: 0.9043 - val_loss: 2.2704 - val_acc: 0.7500\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.2059 - acc: 0.9043 - val_loss: 2.2888 - val_acc: 0.7500\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.2033 - acc: 0.9043 - val_loss: 2.3195 - val_acc: 0.7500\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.2056 - acc: 0.9043 - val_loss: 2.3549 - val_acc: 0.7500\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.2057 - acc: 0.9043 - val_loss: 2.3784 - val_acc: 0.7500\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.2059 - acc: 0.9043 - val_loss: 2.4071 - val_acc: 0.7500\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.2047 - acc: 0.9043 - val_loss: 2.4287 - val_acc: 0.7500\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.2047 - acc: 0.9043 - val_loss: 2.4476 - val_acc: 0.7500\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.2018 - acc: 0.9043 - val_loss: 2.4784 - val_acc: 0.7500\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.2054 - acc: 0.9043 - val_loss: 2.4792 - val_acc: 0.7500\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.2075 - acc: 0.9043 - val_loss: 2.4777 - val_acc: 0.7500\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.2043 - acc: 0.9043 - val_loss: 2.5145 - val_acc: 0.7500\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.2040 - acc: 0.9043 - val_loss: 2.5396 - val_acc: 0.7500\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.2047 - acc: 0.9043 - val_loss: 2.5340 - val_acc: 0.7500\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.2098 - acc: 0.9043 - val_loss: 2.5240 - val_acc: 0.7500\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.2044 - acc: 0.9043 - val_loss: 2.5407 - val_acc: 0.7500\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.2061 - acc: 0.9043 - val_loss: 2.5514 - val_acc: 0.7500\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.2043 - acc: 0.9043 - val_loss: 2.6069 - val_acc: 0.7500\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.2075 - acc: 0.9043 - val_loss: 2.5983 - val_acc: 0.7500\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.2052 - acc: 0.9043 - val_loss: 2.6319 - val_acc: 0.7500\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.2043 - acc: 0.9043 - val_loss: 2.6379 - val_acc: 0.7500\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.2043 - acc: 0.9043 - val_loss: 2.6820 - val_acc: 0.7500\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.2063 - acc: 0.9043 - val_loss: 2.6882 - val_acc: 0.7500\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.2046 - acc: 0.9043 - val_loss: 2.7165 - val_acc: 0.7500\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.2033 - acc: 0.9043 - val_loss: 2.7358 - val_acc: 0.7500\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.2034 - acc: 0.9043 - val_loss: 2.7618 - val_acc: 0.7500\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.2035 - acc: 0.9043 - val_loss: 2.7632 - val_acc: 0.7500\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.2052 - acc: 0.9043 - val_loss: 2.7784 - val_acc: 0.7500\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.2028 - acc: 0.9043 - val_loss: 2.7814 - val_acc: 0.7500\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.2074 - acc: 0.9043 - val_loss: 2.7884 - val_acc: 0.7500\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.2032 - acc: 0.9043 - val_loss: 2.8003 - val_acc: 0.7500\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.2032 - acc: 0.9043 - val_loss: 2.8186 - val_acc: 0.7500\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.2046 - acc: 0.9043 - val_loss: 2.8434 - val_acc: 0.7500\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.2055 - acc: 0.9043 - val_loss: 2.8326 - val_acc: 0.7500\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.2041 - acc: 0.9043 - val_loss: 2.8521 - val_acc: 0.7500\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.2041 - acc: 0.9043 - val_loss: 2.8772 - val_acc: 0.7500\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.2042 - acc: 0.9043 - val_loss: 2.8868 - val_acc: 0.7500\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.2060 - acc: 0.9043 - val_loss: 2.8745 - val_acc: 0.7500\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.2051 - acc: 0.9043 - val_loss: 2.8949 - val_acc: 0.7500\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.2045 - acc: 0.9043 - val_loss: 2.9070 - val_acc: 0.7500\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.2034 - acc: 0.9043 - val_loss: 2.9287 - val_acc: 0.7500\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.2032 - acc: 0.9043 - val_loss: 2.9448 - val_acc: 0.7500\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.2036 - acc: 0.9043 - val_loss: 2.9630 - val_acc: 0.7500\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.2038 - acc: 0.9043 - val_loss: 2.9399 - val_acc: 0.7500\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.2024 - acc: 0.9043 - val_loss: 2.9464 - val_acc: 0.7500\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.2052 - acc: 0.9043 - val_loss: 2.9721 - val_acc: 0.7500\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.2052 - acc: 0.9043 - val_loss: 2.9670 - val_acc: 0.7500\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.2032 - acc: 0.9043 - val_loss: 2.9741 - val_acc: 0.7500\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.2032 - acc: 0.9043 - val_loss: 3.0048 - val_acc: 0.7500\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.2052 - acc: 0.9043 - val_loss: 2.9558 - val_acc: 0.7500\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.2049 - acc: 0.9043 - val_loss: 2.9640 - val_acc: 0.7500\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.2038 - acc: 0.9043 - val_loss: 2.9720 - val_acc: 0.7500\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.2040 - acc: 0.9043 - val_loss: 2.9430 - val_acc: 0.7500\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.2030 - acc: 0.9043 - val_loss: 3.0065 - val_acc: 0.7500\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.2062 - acc: 0.9043 - val_loss: 3.0135 - val_acc: 0.7500\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.2058 - acc: 0.9043 - val_loss: 2.9803 - val_acc: 0.7500\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.2041 - acc: 0.9043 - val_loss: 2.9831 - val_acc: 0.7500\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.2048 - acc: 0.9043 - val_loss: 3.0241 - val_acc: 0.7500\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.2029 - acc: 0.9043 - val_loss: 3.0670 - val_acc: 0.7500\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.2047 - acc: 0.9043 - val_loss: 3.0515 - val_acc: 0.7500\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.2032 - acc: 0.9043 - val_loss: 3.0600 - val_acc: 0.7500\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.2042 - acc: 0.9043 - val_loss: 3.1226 - val_acc: 0.7500\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.2053 - acc: 0.9043 - val_loss: 3.1067 - val_acc: 0.7500\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.2041 - acc: 0.9043 - val_loss: 3.1190 - val_acc: 0.7500\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.2048 - acc: 0.9043 - val_loss: 3.1301 - val_acc: 0.7500\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.2040 - acc: 0.9043 - val_loss: 3.1239 - val_acc: 0.7500\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.2051 - acc: 0.9043 - val_loss: 3.1474 - val_acc: 0.7500\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.2045 - acc: 0.9043 - val_loss: 3.1747 - val_acc: 0.7500\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.2039 - acc: 0.9043 - val_loss: 3.1279 - val_acc: 0.7500\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.2055 - acc: 0.9043 - val_loss: 3.1006 - val_acc: 0.7500\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.2036 - acc: 0.9043 - val_loss: 3.1417 - val_acc: 0.7500\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.2036 - acc: 0.9043 - val_loss: 3.1887 - val_acc: 0.7500\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.2041 - acc: 0.9043 - val_loss: 3.1603 - val_acc: 0.7500\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.2046 - acc: 0.9043 - val_loss: 3.1429 - val_acc: 0.7500\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.2051 - acc: 0.9043 - val_loss: 3.1962 - val_acc: 0.7500\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.2033 - acc: 0.9043 - val_loss: 3.1961 - val_acc: 0.7500\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.2037 - acc: 0.9043 - val_loss: 3.2564 - val_acc: 0.7500\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.2053 - acc: 0.9043 - val_loss: 3.2812 - val_acc: 0.7500\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.2038 - acc: 0.9043 - val_loss: 3.2923 - val_acc: 0.7500\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.2046 - acc: 0.9043 - val_loss: 3.2910 - val_acc: 0.7500\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.2034 - acc: 0.9043 - val_loss: 3.2921 - val_acc: 0.7500\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.2039 - acc: 0.9043 - val_loss: 3.3816 - val_acc: 0.7500\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.2048 - acc: 0.9043 - val_loss: 3.3421 - val_acc: 0.7500\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.2038 - acc: 0.9043 - val_loss: 3.3293 - val_acc: 0.7500\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.2035 - acc: 0.9043 - val_loss: 3.4251 - val_acc: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xfaa9828>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train, batch_size = 10, epochs = 100, verbose=2, validation_data = [X_test, y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Predicting using the training set</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.79284209e-07],\n",
       "       [  9.70875135e-07],\n",
       "       [  9.70475185e-07],\n",
       "       [  9.70506676e-07],\n",
       "       [  9.70475185e-07],\n",
       "       [  9.70530778e-07],\n",
       "       [  9.70475185e-07],\n",
       "       [  9.70475185e-07],\n",
       "       [  9.73435817e-07],\n",
       "       [  9.70475185e-07]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "y_pred[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False]], dtype=bool)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = (y_pred > 0.5)\n",
    "y_pred[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Checking the confusion matrix</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[225,   0],\n",
       "       [ 75,   0]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
